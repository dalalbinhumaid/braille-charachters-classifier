{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## Dataset\n",
    "Retrieved from [Shanks' Braille Charachters Datase](https://www.kaggle.com/shanks0465/braille-character-dataset) which consists of 60 images for each alphabet. Thus, a total of **1560** images.\n",
    "### Dataset Description\n",
    "**Title:** \n",
    "> Braille Character Dataset\n",
    "\n",
    "**Description:** \n",
    "> This dataset was created for the purpose of training a CNN for Braille Character Recognition.\n",
    "\n",
    "**Image Description:** \n",
    "> Each image is a 28x28 image in BW Scale.\n",
    "> Each image name consists of the character alphabet and the number of the image \n",
    "> and the type of data augmentation it went through. (i.e whs - width height shift, rot - Rotation, dim - brightness)\n",
    "\n",
    "**Dataset composition:**\n",
    "> 26 characters * 3 Augmentations * 20 different images of different augmentation values (i.e different shift,rotational and brightness values.)\n",
    "## Approach\n",
    "## Refrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Activation, Dense, Input, SeparableConv2D, Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation\n",
    "Since the data was already cleaned up and pre-processesed. The following code splits the images into two generators a training and a validation generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1404 images belonging to 26 classes.\n",
      "Found 156 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "data = ImageDataGenerator(rotation_range=10, shear_range=10, validation_split=0.1)\n",
    "training_images = data.flow_from_directory('./images/', target_size=(28,28), subset='training')\n",
    "validation_images = data.flow_from_directory('./images/', target_size=(28, 28), subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images):\n",
    "    fig, axes = plt.subplots(1,10, figsize=(28,28))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images, axes):\n",
    "        ax.imshow(img)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(1):\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(int(labels[i]))\n",
    "#         plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 1404\n",
      "Number of batches: 32\n",
      "Number of images in a batch: 44\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_batch, label = training_images.next()\n",
    "print(\"Total training images:\", training_images.n)\n",
    "print(\"Number of batches:\", image_batch.shape[0])\n",
    "print(\"Number of images in a batch:\", len(training_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x186a6431310>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAATcElEQVR4nO3dW4xVZZYH8P8C5FpcLSgKEaoFJIGJgpSEpAlRO2NUHqQTok1ix0k09IMmduLDGMfYPvhAJtPdmYdJJ/SIzUwY2za0woOZQUkHaK+UhpGLjjiEChCwiovcL0KteaitU2rttY77O2fvE9f/l1Tq1Fnn2/tj77PYVWft7/tEVUFEP3xDqu4AEZWDyU4UBJOdKAgmO1EQTHaiIIaVubPW1lbt6Ogoc5dfS606iEjhbVtta5HS99S+efGU7V+7ds1sO3ToUDPuaeRxGzIk7TppbT/lmHZ3d+P48eODviAp2UXkHgD/DGAogH9V1TXW6zs6OrBz505re4X74r1xvLh3gEeMGJEbu3LlitnWe9N6cW/71hvvyy+/NNsOG2a/Ba677jozfvXq1cLbP336tNl2/PjxZtxz6dKl3Jj377548aIZHzt2bKE+fcXqW19fn9nWOidLlizJjRX+70lEhgL4FwD3ApgHYJWIzCu6PSJqrJTfRRYD+ExVD6jqFQB/BHB/fbpFRPWWkuw3ADg04OfD2XPfICKrRaRLRLp6e3sTdkdEKRr+abyqrlXVTlXtnDx5cqN3R0Q5UpL9CIAbB/w8PXuOiJpQSrLvBDBHRH4kIsMB/AzA5vp0i4jqrXDpTVWvisjjAP4L/aW3daq6t4Z2hWKAXZLwyldeWc8rUVn7Hj58uNnWK+N47T1WGckrMaXef5DSvqWlxYyn1uGtf7vXb6+0ZpXOALtUCwAjR4404xbrvWi9z5Pq7Kr6OoDXU7ZBROXg7bJEQTDZiYJgshMFwWQnCoLJThQEk50oiFLHswNp44CtGqJXy/b269U9rbqst+/UMeHeMNKUOv3ly5eTtu3dn2Dxhs96x3XUqFFm3Kqze/32avz79u0z4++9954Zv/nmm3Njt9xyi9m26G3nvLITBcFkJwqCyU4UBJOdKAgmO1EQTHaiIEovvVm8cohXqrHs37/fjB87dsyMjxkzJjc2f/58s23qLKne7LJeac5y4cIFM+6V5lLKit759IbnerOwppR59+zZY8Y3bdqUFF+4cGFubOXKlWbb5cuXm/E8vLITBcFkJwqCyU4UBJOdKAgmO1EQTHaiIJjsREGUWmdXVbNmfOrUKbP9lClTcmPnzp0z227ZssWMb95sT3k/c+bM3NiTTz5ptp0zZ44ZHz16tBn36tFWPdmrg3tDOb17H7xatjXds1cn96ZzTu2b5Z133jHjXh39xIkTZvz999/PjY0bN85sO2PGjNyYNSyYV3aiIJjsREEw2YmCYLITBcFkJwqCyU4UBJOdKIjS6+xWXderq1rjtnfs2GG29ersn3zyiRnv6enJjW3YsMFs+9BDD5lxa1phoHHTbwP+NNbedM5ee2uKbq/G770fUpaL9tpa5xsAuru7zbg33bNVh/fmXjh06FBuzLqPJSnZReQggLMArgG4qqqdKdsjosapx5X9TlU9XoftEFED8W92oiBSk10BbBGRD0Rk9WAvEJHVItIlIl3Hj/MXAKKqpCb7UlW9DcC9AB4TkWXffoGqrlXVTlXtbG1tTdwdERWVlOyqeiT73gPgVQCL69EpIqq/wskuImNEZOxXjwHcDcCef5eIKpPyaXwbgFezOu4wAP+hqv9pNRARc3yztzywVWffvXu32fbgwYNmfOLEiWbcGnv99ttvm23vvPNOM26NTwbsOesBu17t1ei9Orw35tyLW/POe0sue1LuP/D6PW3aNDM+ffp0M+6NtbfmMLDmbQCAWbNm5cZGjBiRGyuc7Kp6AMCtRdsTUblYeiMKgslOFASTnSgIJjtREEx2oiBKX7LZK/UUbesNh7RKfgBw8uRJM26VBb3hjB5rGCjgTyVtlSS9oZzetr2+edu3loT2ptD2htd6fbN4pbfZs2eb8blz55pxrxzb0tKSG5s0aZLZtr29PTdmnU9e2YmCYLITBcFkJwqCyU4UBJOdKAgmO1EQTHaiIEqvs1vDMb2pha2664IFC8y2ixfb82ps3brVjFu1z6lTp5ptlyxZYsat6X8B/7hYQz0vXbpktvXqzd59EVaNH7Dryd6+vSGw3jDSYcPy395ejf/WW+0Bnc8884wZ37Ztmxm3hrF6U4sXnUKbV3aiIJjsREEw2YmCYLITBcFkJwqCyU4UBJOdKIhS6+x9fX1mrdyrq1rTPS9atMjdt2XevHlm3BoP700F7Y279qZEturFXnuvJmtNPQz4fffuAbDi3hwDqdNYW/cAeOP4vanFvXPS0dFhxi3e+8E6btZ9EbyyEwXBZCcKgslOFASTnSgIJjtREEx2oiCY7ERBlFpnHzJkiFlL9+qulgkTJphxb0z5/PnzzbhVv/SWVPbGhKfMpe/xarYpNV3Ar+OnnFOPV+u2avxejd47Lt46BZ6Uvlnvl6Q6u4isE5EeEdkz4LlJIvKGiOzPvtt3IBBR5Wr5Nf4PAO751nNPAdiqqnMAbM1+JqIm5ia7qm4H8O21ke4HsD57vB7Aivp2i4jqregHdG2qejR7fAxAW94LRWS1iHSJSFdvb2/B3RFRquRP47X/E5rcT2lUda2qdqpqZ+oCiERUXNFk/1xE2gEg+95Tvy4RUSMUTfbNAB7OHj8MYFN9ukNEjeLW2UXkJQB3AGgVkcMAfgVgDYA/icgjALoBPFDLzkTEHB/t1RetOdC9+cu9mmxbW+7HDgDS6sXeOuPev9tj1bq9Gr5XT05t30jeObH65s057/HeT9770Tpn3r/L2rd1vtxkV9VVOaGfeG2JqHnwdlmiIJjsREEw2YmCYLITBcFkJwqi1CGuqmqWz4YPH262t8p2KaUOwC8xWcsqe8sie0NgG6nK4bWAPZTTO2cebxpsswzllM5Sy6HeeznluFh9s97nvLITBcFkJwqCyU4UBJOdKAgmO1EQTHaiIJjsREGUXme3hhZ6y+havKGW3tLCKVMLezVVr2/ePQAeq723be+4pNbpiy4vDPj1Zi+espS1J2W56FriFu/9lodXdqIgmOxEQTDZiYJgshMFwWQnCoLJThQEk50oiFLr7N5U0h6rRp86nt2r8VvxlKWDgcbW2Rstpc7u3X/g1ZNTa90pvH2nTAfttS167wKv7ERBMNmJgmCyEwXBZCcKgslOFASTnSgIJjtREKXX2a36Yko92quTpy4tbNX4vZqr17dGz91epd7e3tzY+PHjzbbevPDeOU0ZS+/xzrm3JLR1D4DXN+telaR540VknYj0iMieAc89JyJHRGRX9nWftx0iqlYtl7s/ALhnkOd/q6oLsq/X69stIqo3N9lVdTuAkyX0hYgaKOUP2cdF5KPs1/yJeS8SkdUi0iUiXdbfb0TUWEWT/XcAZgFYAOAogF/nvVBV16pqp6p2Tp48ueDuiChVoWRX1c9V9Zqq9gH4PYDF9e0WEdVboWQXkfYBP/4UwJ681xJRc3Dr7CLyEoA7ALSKyGEAvwJwh4gsAKAADgL4RS078+aNLzofNgBcvHjRjHu17j177P+vdu/enRu7/fbbzbYzZsww46NHjzbjX3zxhRkfN25cbswb6+6N+fbqxc8++6wZt/q+Zs0as21LS4sZ986p1XdvXgWv1u0d1/Pnz5txi/fv8u5HyeMmu6quGuTpFwrtjYgqw9tliYJgshMFwWQnCoLJThQEk50oiNKHuFrlNa/MYw0rHDVqlNl23759Zvy1114z4zt27MiNbdu2zWz7/PPPm3FvuOSECRPM+JkzZ3JjXvnK2/ejjz5qxl9++WUzPnfu3NyYV3p74oknzPjMmTPNuFXCOnv2rNnWGz7rvVcvX75sxi3eOSnalld2oiCY7ERBMNmJgmCyEwXBZCcKgslOFASTnSiIUuvsqazhmN60w9u3bzfjb775phn/9NNPc2OHDh0y227cuNGMr1y50ox7tXKrpmsNf62FV/P1hvdeuHAhN/biiy+abZcvX27Gr7/+ejNuHbexY8eabT0nTpww41euXCm87ZQ6e9JU0kT0w8BkJwqCyU4UBJOdKAgmO1EQTHaiIJjsREGUWmfv6+vDuXPncuNePdla7tmbSvrdd98140eOHDHjkyZNyo15Nf5XXnnFjN91111mvK2tzYynrLTjTVPtjfs+edJeBtCq+1rnEwCmTJlixr05DKwa//Hjx5P27dXprfc54E9F3Qi8shMFwWQnCoLJThQEk50oCCY7URBMdqIgmOxEQZQ+nt2bj9viLaNr8eb59pbBtdpb9VwAWLZsmRn37hHwWDVd73i3t7cnxQ8fPmzGe3p6cmPTp08323Z3d5vxadOmmXFrvLu3jLbn2LFjZty7B8Acd+6cM2vtBStH3MwTkRtF5C8isk9E9orIE9nzk0TkDRHZn32f6G2LiKpTy2X2KoAnVXUegCUAHhOReQCeArBVVecA2Jr9TERNyk12VT2qqh9mj88C+BjADQDuB7A+e9l6ACsa1EciqoPv9Qe0iHQAWAjgPQBtqno0Cx0DMOgN3CKyWkS6RKTLux+ZiBqn5mQXkRYAGwH8UlW/sZKg9n/aMOgnDqq6VlU7VbWztbU1qbNEVFxNyS4i16E/0Teo6p+zpz8XkfYs3g4g/2NXIqqcW3qT/s/yXwDwsar+ZkBoM4CHAazJvm/ytjVkyBCMHDkyN+4Np7SGRHqljqVLl5rx06dPm/EDBw7kxrxpg+fNm2fGp06dasY91tBgb1pir2w4e/ZsM/7WW2+Z8YULF+bGVqxYYbZdtGiRGfemkr506VJuzCu1jhkzxox75+z8+fNm3Fxa2Sm9WUtRW21rqbP/GMDPAewWkV3Zc0+jP8n/JCKPAOgG8EAN2yKiirjJrqp/BZBXqf9JfbtDRI3C22WJgmCyEwXBZCcKgslOFASTnSiIplqy2aqLAmnL7N59991m3Juuee/evbkxr2Z72223mXFvqOapU6fM+IQJE3JjXs3Wmwb76aefNuMPPvigGbfOmTU9N+BPNe3dQ1C0Hg34w469OvrEifYgUOs94w3lto5L0hBXIvphYLITBcFkJwqCyU4UBJOdKAgmO1EQTHaiIEqts6sqrl69mhv3xqRbY+G9Gv3MmTPN+E033WTGrfHw3lLTXk03tWZ75syZ3Jh3TK1aNODX+GfNmmXGLd4cAuPHjzfj3jm3/m3eksnecUuZKjpV0SnVeWUnCoLJThQEk50oCCY7URBMdqIgmOxEQTDZiYIotc4uImbt06v5WrVLb1x2qsmTJxdum7LUdC3GjRvXsG17Nf4UXh3dM3r06Dr1pP68cz506NCSevL/eGUnCoLJThQEk50oCCY7URBMdqIgmOxEQTDZiYJwk11EbhSRv4jIPhHZKyJPZM8/JyJHRGRX9nVf47tLREXVclPNVQBPquqHIjIWwAci8kYW+62q/lPjukdE9VLL+uxHARzNHp8VkY8B3NDojhFRfX2vv9lFpAPAQgDvZU89LiIficg6ERn0vkoRWS0iXSLS1dvbm9ZbIiqs5mQXkRYAGwH8UlXPAPgdgFkAFqD/yv/rwdqp6lpV7VTVzpT7y4koTU3JLiLXoT/RN6jqnwFAVT9X1Wuq2gfg9wAWN66bRJSqlk/jBcALAD5W1d8MeL59wMt+CmBP/btHRPVSy6fxPwbwcwC7RWRX9tzTAFaJyAIACuAggF80oH9EVCe1fBr/VwCDDc59vf7dIaJG4R10REEw2YmCYLITBcFkJwqCyU4UBJOdKIhSp5IGGj+tMhENjld2oiCY7ERBMNmJgmCyEwXBZCcKgslOFASTnSgIsZZBrvvORHoBdA94qhXA8dI68P00a9+atV8A+1ZUPfs2U1UHnf+t1GT/zs5FulS1s7IOGJq1b83aL4B9K6qsvvHXeKIgmOxEQVSd7Gsr3r+lWfvWrP0C2LeiSulbpX+zE1F5qr6yE1FJmOxEQVSS7CJyj4j8j4h8JiJPVdGHPCJyUER2Z8tQd1Xcl3Ui0iMiewY8N0lE3hCR/dn3QdfYq6hvTbGMt7HMeKXHrurlz0v/m11EhgL4FMDfAjgMYCeAVaq6r9SO5BCRgwA6VbXyGzBEZBmAcwD+TVX/JnvuHwGcVNU12X+UE1X175ukb88BOFf1Mt7ZakXtA5cZB7ACwN+hwmNn9OsBlHDcqriyLwbwmaoeUNUrAP4I4P4K+tH0VHU7gJPfevp+AOuzx+vR/2YpXU7fmoKqHlXVD7PHZwF8tcx4pcfO6Fcpqkj2GwAcGvDzYTTXeu8KYIuIfCAiq6vuzCDaVPVo9vgYgLYqOzMIdxnvMn1rmfGmOXZFlj9PxQ/ovmupqt4G4F4Aj2W/rjYl7f8brJlqpzUt412WQZYZ/1qVx67o8uepqkj2IwBuHPDz9Oy5pqCqR7LvPQBeRfMtRf35VyvoZt97Ku7P15ppGe/BlhlHExy7Kpc/ryLZdwKYIyI/EpHhAH4GYHMF/fgOERmTfXACERkD4G4031LUmwE8nD1+GMCmCvvyDc2yjHfeMuOo+NhVvvy5qpb+BeA+9H8i/78A/qGKPuT06yYA/5197a26bwBeQv+vdV+i/7ONRwBcD2ArgP0A3gQwqYn69u8AdgP4CP2J1V5R35ai/1f0jwDsyr7uq/rYGf0q5bjxdlmiIPgBHVEQTHaiIJjsREEw2YmCYLITBcFkJwqCyU4UxP8BG/DJGpoWI0EAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "braille_a = image.load_img('./images/z/z1.JPG0rot.jpg')\n",
    "plt.imshow(braille_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_41 (Conv2D)          (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " global_max_pooling2d_7 (Glo  (None, 64)               0         \n",
      " balMaxPooling2D)                                                \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 26)                1690      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,242\n",
      "Trainable params: 25,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(training_images.image_shape)\n",
    "# model = Sequential([Input(shape=(28, 28, 3)),\n",
    "#                     Dense(64, activation='relu'),\n",
    "#                     Dense(26, activation='softmax')\n",
    "#                     ])\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# early_stopping = EarlyStopping(patience=20, verbose=1)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(28, 28, 3)))  #\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(26, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "              \n",
    "early_stopping = EarlyStopping(patience=20, verbose=1)\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 41.9403 - accuracy: 0.0285 - val_loss: 9.4115 - val_accuracy: 0.0577\n",
      "Epoch 2/150\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 6.4376 - accuracy: 0.0613 - val_loss: 4.6433 - val_accuracy: 0.0833\n",
      "Epoch 3/150\n",
      "44/44 [==============================] - 2s 34ms/step - loss: 4.4959 - accuracy: 0.0833 - val_loss: 4.2211 - val_accuracy: 0.1218\n",
      "Epoch 4/150\n",
      "44/44 [==============================] - 1s 34ms/step - loss: 4.2186 - accuracy: 0.1026 - val_loss: 4.2522 - val_accuracy: 0.1346\n",
      "Epoch 5/150\n",
      "44/44 [==============================] - 2s 34ms/step - loss: 3.8087 - accuracy: 0.1311 - val_loss: 3.7133 - val_accuracy: 0.1346\n",
      "Epoch 6/150\n",
      "44/44 [==============================] - 1s 34ms/step - loss: 3.5224 - accuracy: 0.1496 - val_loss: 3.4462 - val_accuracy: 0.1667\n",
      "Epoch 7/150\n",
      "44/44 [==============================] - 2s 35ms/step - loss: 3.3859 - accuracy: 0.1681 - val_loss: 3.1167 - val_accuracy: 0.2179\n",
      "Epoch 8/150\n",
      "44/44 [==============================] - 2s 35ms/step - loss: 3.2830 - accuracy: 0.1880 - val_loss: 3.2935 - val_accuracy: 0.2051\n",
      "Epoch 9/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 3.1925 - accuracy: 0.1923 - val_loss: 3.0062 - val_accuracy: 0.2628\n",
      "Epoch 10/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 2.8894 - accuracy: 0.2229 - val_loss: 3.0138 - val_accuracy: 0.2244\n",
      "Epoch 11/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 2.7833 - accuracy: 0.2407 - val_loss: 2.7200 - val_accuracy: 0.3077\n",
      "Epoch 12/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 2.6372 - accuracy: 0.2628 - val_loss: 2.7971 - val_accuracy: 0.2500\n",
      "Epoch 13/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 2.5366 - accuracy: 0.2892 - val_loss: 2.7155 - val_accuracy: 0.2628\n",
      "Epoch 14/150\n",
      "44/44 [==============================] - 2s 35ms/step - loss: 2.4954 - accuracy: 0.2984 - val_loss: 2.6245 - val_accuracy: 0.3141\n",
      "Epoch 15/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 2.3319 - accuracy: 0.3362 - val_loss: 2.3542 - val_accuracy: 0.3333\n",
      "Epoch 16/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 2.2309 - accuracy: 0.3533 - val_loss: 2.4080 - val_accuracy: 0.3590\n",
      "Epoch 17/150\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 2.1205 - accuracy: 0.3789 - val_loss: 2.1758 - val_accuracy: 0.4038\n",
      "Epoch 18/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 2.1312 - accuracy: 0.3932 - val_loss: 2.0557 - val_accuracy: 0.3910\n",
      "Epoch 19/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 1.9861 - accuracy: 0.4152 - val_loss: 2.1322 - val_accuracy: 0.3718\n",
      "Epoch 20/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 2.0448 - accuracy: 0.4160 - val_loss: 2.0697 - val_accuracy: 0.3718\n",
      "Epoch 21/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 1.9170 - accuracy: 0.4387 - val_loss: 1.8006 - val_accuracy: 0.4615\n",
      "Epoch 22/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 1.8316 - accuracy: 0.4665 - val_loss: 1.8263 - val_accuracy: 0.4808\n",
      "Epoch 23/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 1.7107 - accuracy: 0.4829 - val_loss: 1.8663 - val_accuracy: 0.4872\n",
      "Epoch 24/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 1.5790 - accuracy: 0.5406 - val_loss: 1.6570 - val_accuracy: 0.5000\n",
      "Epoch 25/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 1.5170 - accuracy: 0.5477 - val_loss: 1.8542 - val_accuracy: 0.4615\n",
      "Epoch 26/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 1.5216 - accuracy: 0.5627 - val_loss: 1.6299 - val_accuracy: 0.5128\n",
      "Epoch 27/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 1.4272 - accuracy: 0.5791 - val_loss: 1.4513 - val_accuracy: 0.5897\n",
      "Epoch 28/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 1.2823 - accuracy: 0.5983 - val_loss: 1.2462 - val_accuracy: 0.6603\n",
      "Epoch 29/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 1.2695 - accuracy: 0.6182 - val_loss: 1.3677 - val_accuracy: 0.5385\n",
      "Epoch 30/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 1.3047 - accuracy: 0.6140 - val_loss: 1.4084 - val_accuracy: 0.5064\n",
      "Epoch 31/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 1.2360 - accuracy: 0.6068 - val_loss: 1.3426 - val_accuracy: 0.6154\n",
      "Epoch 32/150\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 1.1332 - accuracy: 0.6595 - val_loss: 1.2768 - val_accuracy: 0.6026\n",
      "Epoch 33/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 1.2183 - accuracy: 0.6147 - val_loss: 1.1773 - val_accuracy: 0.6346\n",
      "Epoch 34/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 1.1493 - accuracy: 0.6510 - val_loss: 1.3439 - val_accuracy: 0.6474\n",
      "Epoch 35/150\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 1.1562 - accuracy: 0.6538 - val_loss: 1.2377 - val_accuracy: 0.6154\n",
      "Epoch 36/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 1.1083 - accuracy: 0.6759 - val_loss: 1.1861 - val_accuracy: 0.6410\n",
      "Epoch 37/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 1.0593 - accuracy: 0.6830 - val_loss: 1.0788 - val_accuracy: 0.6667\n",
      "Epoch 38/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.9793 - accuracy: 0.6809 - val_loss: 1.2315 - val_accuracy: 0.6346\n",
      "Epoch 39/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.9541 - accuracy: 0.7144 - val_loss: 1.1438 - val_accuracy: 0.6731\n",
      "Epoch 40/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.9509 - accuracy: 0.6923 - val_loss: 1.0265 - val_accuracy: 0.6538\n",
      "Epoch 41/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.8922 - accuracy: 0.7365 - val_loss: 1.0162 - val_accuracy: 0.7179\n",
      "Epoch 42/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.9109 - accuracy: 0.7187 - val_loss: 1.0488 - val_accuracy: 0.6795\n",
      "Epoch 43/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.8372 - accuracy: 0.7365 - val_loss: 0.9995 - val_accuracy: 0.6667\n",
      "Epoch 44/150\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.8800 - accuracy: 0.7301 - val_loss: 0.9359 - val_accuracy: 0.7308\n",
      "Epoch 45/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.8276 - accuracy: 0.7372 - val_loss: 0.9590 - val_accuracy: 0.7436\n",
      "Epoch 46/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.8221 - accuracy: 0.7429 - val_loss: 0.9112 - val_accuracy: 0.7500\n",
      "Epoch 47/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.9620 - accuracy: 0.7094 - val_loss: 0.8468 - val_accuracy: 0.7436\n",
      "Epoch 48/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.7962 - accuracy: 0.7407 - val_loss: 0.8164 - val_accuracy: 0.7308\n",
      "Epoch 49/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.7890 - accuracy: 0.7422 - val_loss: 0.8905 - val_accuracy: 0.7244\n",
      "Epoch 50/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.8181 - accuracy: 0.7350 - val_loss: 1.1229 - val_accuracy: 0.6667\n",
      "Epoch 51/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.7375 - accuracy: 0.7678 - val_loss: 0.9689 - val_accuracy: 0.7051\n",
      "Epoch 52/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.8149 - accuracy: 0.7393 - val_loss: 0.9944 - val_accuracy: 0.7115\n",
      "Epoch 53/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.7962 - accuracy: 0.7450 - val_loss: 1.1316 - val_accuracy: 0.6538\n",
      "Epoch 54/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.8235 - accuracy: 0.7343 - val_loss: 0.9684 - val_accuracy: 0.6667\n",
      "Epoch 55/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.7421 - accuracy: 0.7671 - val_loss: 0.9691 - val_accuracy: 0.7436\n",
      "Epoch 56/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.8133 - accuracy: 0.7386 - val_loss: 0.9047 - val_accuracy: 0.7436\n",
      "Epoch 57/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.7813 - accuracy: 0.7614 - val_loss: 1.0118 - val_accuracy: 0.7308\n",
      "Epoch 58/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.6919 - accuracy: 0.7863 - val_loss: 0.7907 - val_accuracy: 0.7436\n",
      "Epoch 59/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.6159 - accuracy: 0.7991 - val_loss: 0.7533 - val_accuracy: 0.7692\n",
      "Epoch 60/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.6372 - accuracy: 0.7984 - val_loss: 0.7860 - val_accuracy: 0.7628\n",
      "Epoch 61/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.7069 - accuracy: 0.7863 - val_loss: 0.8716 - val_accuracy: 0.7500\n",
      "Epoch 62/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.6601 - accuracy: 0.7906 - val_loss: 0.8687 - val_accuracy: 0.7308\n",
      "Epoch 63/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.7337 - accuracy: 0.7621 - val_loss: 0.8012 - val_accuracy: 0.7244\n",
      "Epoch 64/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.7204 - accuracy: 0.7650 - val_loss: 0.8713 - val_accuracy: 0.7308\n",
      "Epoch 65/150\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.6196 - accuracy: 0.8041 - val_loss: 0.8601 - val_accuracy: 0.7692\n",
      "Epoch 66/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.7045 - accuracy: 0.7756 - val_loss: 0.7752 - val_accuracy: 0.7564\n",
      "Epoch 67/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.6922 - accuracy: 0.7707 - val_loss: 1.1331 - val_accuracy: 0.7051\n",
      "Epoch 68/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.6530 - accuracy: 0.7863 - val_loss: 0.6718 - val_accuracy: 0.7564\n",
      "Epoch 69/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.6249 - accuracy: 0.7956 - val_loss: 0.8034 - val_accuracy: 0.7436\n",
      "Epoch 70/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.6508 - accuracy: 0.8041 - val_loss: 0.8061 - val_accuracy: 0.7756\n",
      "Epoch 71/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5864 - accuracy: 0.8120 - val_loss: 0.7005 - val_accuracy: 0.8141\n",
      "Epoch 72/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.6193 - accuracy: 0.7949 - val_loss: 0.9794 - val_accuracy: 0.7051\n",
      "Epoch 73/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.6836 - accuracy: 0.7813 - val_loss: 0.6837 - val_accuracy: 0.8013\n",
      "Epoch 74/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.6087 - accuracy: 0.8105 - val_loss: 0.6511 - val_accuracy: 0.8077\n",
      "Epoch 75/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.6281 - accuracy: 0.8027 - val_loss: 0.7581 - val_accuracy: 0.8013\n",
      "Epoch 76/150\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.5408 - accuracy: 0.8333 - val_loss: 0.7512 - val_accuracy: 0.7949\n",
      "Epoch 77/150\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.5600 - accuracy: 0.8283 - val_loss: 0.6821 - val_accuracy: 0.8077\n",
      "Epoch 78/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5903 - accuracy: 0.8155 - val_loss: 0.6804 - val_accuracy: 0.8205\n",
      "Epoch 79/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.6356 - accuracy: 0.7899 - val_loss: 0.7708 - val_accuracy: 0.7436\n",
      "Epoch 80/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4558 - accuracy: 0.8540 - val_loss: 0.7611 - val_accuracy: 0.7436\n",
      "Epoch 81/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.5541 - accuracy: 0.8226 - val_loss: 0.6606 - val_accuracy: 0.8205\n",
      "Epoch 82/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.5963 - accuracy: 0.8148 - val_loss: 0.6811 - val_accuracy: 0.8205\n",
      "Epoch 83/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4998 - accuracy: 0.8390 - val_loss: 0.7627 - val_accuracy: 0.7885\n",
      "Epoch 84/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5805 - accuracy: 0.8091 - val_loss: 0.9619 - val_accuracy: 0.7308\n",
      "Epoch 85/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.5978 - accuracy: 0.8070 - val_loss: 0.7502 - val_accuracy: 0.7564\n",
      "Epoch 86/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.5708 - accuracy: 0.8048 - val_loss: 0.8709 - val_accuracy: 0.7244\n",
      "Epoch 87/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.5357 - accuracy: 0.8397 - val_loss: 0.5009 - val_accuracy: 0.8526\n",
      "Epoch 88/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.5294 - accuracy: 0.8397 - val_loss: 0.6620 - val_accuracy: 0.7692\n",
      "Epoch 89/150\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.6338 - accuracy: 0.8041 - val_loss: 0.7827 - val_accuracy: 0.7500\n",
      "Epoch 90/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5159 - accuracy: 0.8355 - val_loss: 0.6031 - val_accuracy: 0.8205\n",
      "Epoch 91/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5299 - accuracy: 0.8298 - val_loss: 0.6748 - val_accuracy: 0.8333\n",
      "Epoch 92/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.5771 - accuracy: 0.8291 - val_loss: 0.7721 - val_accuracy: 0.7885\n",
      "Epoch 93/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5766 - accuracy: 0.8255 - val_loss: 0.5207 - val_accuracy: 0.8590\n",
      "Epoch 94/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.5788 - accuracy: 0.8155 - val_loss: 0.4819 - val_accuracy: 0.8526\n",
      "Epoch 95/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5270 - accuracy: 0.8326 - val_loss: 0.4992 - val_accuracy: 0.8590\n",
      "Epoch 96/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5990 - accuracy: 0.8226 - val_loss: 0.6125 - val_accuracy: 0.8077\n",
      "Epoch 97/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4896 - accuracy: 0.8362 - val_loss: 0.6918 - val_accuracy: 0.7756\n",
      "Epoch 98/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5258 - accuracy: 0.8376 - val_loss: 0.4841 - val_accuracy: 0.8654\n",
      "Epoch 99/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.6255 - accuracy: 0.7984 - val_loss: 0.8151 - val_accuracy: 0.7756\n",
      "Epoch 100/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5520 - accuracy: 0.8191 - val_loss: 0.5140 - val_accuracy: 0.8462\n",
      "Epoch 101/150\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.4947 - accuracy: 0.8476 - val_loss: 0.6716 - val_accuracy: 0.8269\n",
      "Epoch 102/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5253 - accuracy: 0.8462 - val_loss: 0.5334 - val_accuracy: 0.8462\n",
      "Epoch 103/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.4365 - accuracy: 0.8661 - val_loss: 0.6920 - val_accuracy: 0.7949\n",
      "Epoch 104/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5119 - accuracy: 0.8476 - val_loss: 0.7436 - val_accuracy: 0.7628\n",
      "Epoch 105/150\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.5882 - accuracy: 0.8269 - val_loss: 0.6689 - val_accuracy: 0.8077\n",
      "Epoch 106/150\n",
      "44/44 [==============================] - 2s 35ms/step - loss: 0.4252 - accuracy: 0.8640 - val_loss: 0.7096 - val_accuracy: 0.7885\n",
      "Epoch 107/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4597 - accuracy: 0.8561 - val_loss: 0.6254 - val_accuracy: 0.8397\n",
      "Epoch 108/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.4364 - accuracy: 0.8675 - val_loss: 0.4482 - val_accuracy: 0.8462\n",
      "Epoch 109/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.4646 - accuracy: 0.8397 - val_loss: 0.6716 - val_accuracy: 0.8077\n",
      "Epoch 110/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5211 - accuracy: 0.8362 - val_loss: 0.8747 - val_accuracy: 0.8077\n",
      "Epoch 111/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4970 - accuracy: 0.8483 - val_loss: 0.4977 - val_accuracy: 0.8141\n",
      "Epoch 112/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.4652 - accuracy: 0.8433 - val_loss: 0.5704 - val_accuracy: 0.8526\n",
      "Epoch 113/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.3997 - accuracy: 0.8761 - val_loss: 0.5066 - val_accuracy: 0.8333\n",
      "Epoch 114/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4203 - accuracy: 0.8590 - val_loss: 0.5538 - val_accuracy: 0.8462\n",
      "Epoch 115/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.3998 - accuracy: 0.8654 - val_loss: 0.5461 - val_accuracy: 0.8526\n",
      "Epoch 116/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4223 - accuracy: 0.8611 - val_loss: 0.4229 - val_accuracy: 0.8718\n",
      "Epoch 117/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.4805 - accuracy: 0.8511 - val_loss: 0.5817 - val_accuracy: 0.8333\n",
      "Epoch 118/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4735 - accuracy: 0.8490 - val_loss: 0.4947 - val_accuracy: 0.8590\n",
      "Epoch 119/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4252 - accuracy: 0.8661 - val_loss: 0.6008 - val_accuracy: 0.8397\n",
      "Epoch 120/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.4379 - accuracy: 0.8583 - val_loss: 0.6348 - val_accuracy: 0.8269\n",
      "Epoch 121/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4219 - accuracy: 0.8739 - val_loss: 0.4842 - val_accuracy: 0.8397\n",
      "Epoch 122/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.4922 - accuracy: 0.8511 - val_loss: 0.9794 - val_accuracy: 0.7821\n",
      "Epoch 123/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.5215 - accuracy: 0.8376 - val_loss: 0.9226 - val_accuracy: 0.7821\n",
      "Epoch 124/150\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.4482 - accuracy: 0.8618 - val_loss: 0.5350 - val_accuracy: 0.8333\n",
      "Epoch 125/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4188 - accuracy: 0.8689 - val_loss: 0.4969 - val_accuracy: 0.8397\n",
      "Epoch 126/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4767 - accuracy: 0.8654 - val_loss: 0.6144 - val_accuracy: 0.8269\n",
      "Epoch 127/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4803 - accuracy: 0.8604 - val_loss: 0.6479 - val_accuracy: 0.8397\n",
      "Epoch 128/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4824 - accuracy: 0.8561 - val_loss: 0.4783 - val_accuracy: 0.8590\n",
      "Epoch 129/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4192 - accuracy: 0.8625 - val_loss: 0.7629 - val_accuracy: 0.7756\n",
      "Epoch 130/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4848 - accuracy: 0.8554 - val_loss: 0.6360 - val_accuracy: 0.8333\n",
      "Epoch 131/150\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.4321 - accuracy: 0.8689 - val_loss: 0.5433 - val_accuracy: 0.8526\n",
      "Epoch 132/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4156 - accuracy: 0.8689 - val_loss: 0.8010 - val_accuracy: 0.8013\n",
      "Epoch 133/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4676 - accuracy: 0.8575 - val_loss: 0.5329 - val_accuracy: 0.8141\n",
      "Epoch 134/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.4385 - accuracy: 0.8604 - val_loss: 0.5190 - val_accuracy: 0.8654\n",
      "Epoch 135/150\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.3606 - accuracy: 0.8825 - val_loss: 0.5021 - val_accuracy: 0.8526\n",
      "Epoch 136/150\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.3998 - accuracy: 0.8853 - val_loss: 0.5475 - val_accuracy: 0.8397\n",
      "Epoch 00136: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model = model.fit(training_images,\n",
    "                          validation_data=validation_images,\n",
    "                          epochs=150,\n",
    "                          batch_size=32,\n",
    "                          callbacks=[early_stopping],\n",
    "                          verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
